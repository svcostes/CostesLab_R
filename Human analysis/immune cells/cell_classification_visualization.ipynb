{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1JewjBir4tY"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2-PANEL OUTPUT PER FIELD (DAPI+53BP1 + classified overlay)\n",
        "#\n",
        "# What this script does:\n",
        "#   1) Finds one \"anchor\" DAPI image per field-of-view (FOV), even if DAPI is not at Z0010.\n",
        "#   2) Builds max-intensity projections (MIPs) across Z for:\n",
        "#        - AF488 (53BP1 visualization)\n",
        "#        - AF594 and AF647 (CRITICAL: classification uses these)\n",
        "#   3) Segments nuclei from the anchor DAPI image (Cellpose if available; Otsu fallback).\n",
        "#   4) Classifies nuclei using per-well AF594/AF647 cutoffs (exclusive calls):\n",
        "#        - AF594-only => purple\n",
        "#        - AF647-only => red\n",
        "#        - otherwise => grayscale background\n",
        "#   5) Saves a 2-panel PNG per FOV and logs metrics to a CSV.\n",
        "#\n",
        "# Notes:\n",
        "#   - This script is meant for generating readable panels, not quantitative normalization.\n",
        "# ============================================================\n",
        "\n",
        "import os, re, glob, csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tifffile import imread\n",
        "\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.morphology import remove_small_holes, remove_small_objects, dilation, disk\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage.measure import label\n",
        "\n",
        "# ----------------------------\n",
        "# Optional Cellpose (recommended)\n",
        "# ----------------------------\n",
        "USE_CELLPOSE = True\n",
        "try:\n",
        "    from cellpose import models\n",
        "except Exception:\n",
        "    USE_CELLPOSE = False\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "FORCE_RERUN = True  # set False to skip anchors already processed\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/representative images\"\n",
        "cutoff_csv_path = \"/content/drive/My Drive/per_well_cutoffs_all_plates_AF594_AF647_0.975_WITH_secondary_floors_high.csv\"\n",
        "\n",
        "output_dir = \"/content/drive/My Drive/Output_MIP_panel_1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "csv_out_path   = os.path.join(output_dir, \"panel_metrics.csv\")\n",
        "done_list_path = os.path.join(output_dir, \"panels_done.txt\")\n",
        "\n",
        "TARGET_PLATES = {934}\n",
        "\n",
        "# DAPI display window (fixed)\n",
        "DISP_DAPI = (500, 2500)\n",
        "\n",
        "# ----------------------------\n",
        "# AF488 display parameters (NOT aggressive)\n",
        "#   - percentiles for windowing\n",
        "#   - gamma=1.0 means no extra darkening\n",
        "# ----------------------------\n",
        "AF488_P_LO  = 1.0\n",
        "AF488_P_HI  = 99.7\n",
        "AF488_GAMMA = 1.0\n",
        "\n",
        "# Z-range used for max projections\n",
        "Z_RANGE = range(0, 21)  # Z0000..Z0020 inclusive\n",
        "\n",
        "CHANNEL_TAGS = {\n",
        "    \"DAPI\":  (\"C00\", \"DAPI\"),\n",
        "    \"AF488\": (\"C01\", \"AF488\"),  # 53BP1\n",
        "    \"AF594\": (\"C02\", \"AF594\"),\n",
        "    \"AF647\": (\"C03\", \"AF647\"),\n",
        "}\n",
        "\n",
        "# CSV output columns\n",
        "COLS_ORDER = [\n",
        "    \"image_anchor\", \"panel_path\", \"plate\", \"well\",\n",
        "    \"cutoff_594\", \"cutoff_647\",\n",
        "    \"af488_vmin\", \"af488_vmax\", \"af488_gamma\",\n",
        "    \"n_nuclei\", \"n_594_only\", \"n_647_only\", \"n_unclassified\"\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# Resumable helpers\n",
        "# ============================================================\n",
        "def load_completed_sets():\n",
        "    \"\"\"Collect anchors already processed based on CSV + text log.\"\"\"\n",
        "    completed = set()\n",
        "\n",
        "    if os.path.exists(csv_out_path):\n",
        "        try:\n",
        "            df_prev = pd.read_csv(csv_out_path)\n",
        "            if \"image_anchor\" in df_prev.columns:\n",
        "                completed.update(df_prev[\"image_anchor\"].astype(str).tolist())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if os.path.exists(done_list_path):\n",
        "        try:\n",
        "            with open(done_list_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        completed.add(line)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return completed\n",
        "\n",
        "\n",
        "def append_row_to_csv(row_dict):\n",
        "    \"\"\"Append one row to the metrics CSV + mark the anchor as done.\"\"\"\n",
        "    row = {k: row_dict.get(k, None) for k in COLS_ORDER}\n",
        "    write_header = not os.path.exists(csv_out_path)\n",
        "\n",
        "    with open(csv_out_path, \"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=COLS_ORDER)\n",
        "        if write_header:\n",
        "            w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "    with open(done_list_path, \"a\") as f:\n",
        "        f.write(f\"{row['image_anchor']}\\n\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Plate / well parsing\n",
        "# ============================================================\n",
        "def parse_plate_from_name(fname):\n",
        "    \"\"\"Plate is the leading integer token at the start of the filename.\"\"\"\n",
        "    m = re.match(r\"^(\\d+)_\", os.path.basename(fname))\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "def parse_folder_well_from_path(path):\n",
        "    \"\"\"\n",
        "    Well is expected to be the last underscore token of a folder name, e.g.:\n",
        "      .../934_Gamma_1_4hr_CD4_CD19_B11/...\n",
        "    \"\"\"\n",
        "    norm = path.replace(\"\\\\\", \"/\")\n",
        "    parts = norm.split(\"/\")\n",
        "\n",
        "    # search backwards through folders\n",
        "    for part in parts[::-1]:\n",
        "        if part.lower().endswith(\".tif\"):\n",
        "            continue\n",
        "        last = part.split(\"_\")[-1]\n",
        "        if re.fullmatch(r\"[A-H]\\d{1,2}\", last):\n",
        "            return last\n",
        "\n",
        "    # fallback: if well appears inside filename like _B11_\n",
        "    bn = os.path.basename(norm)\n",
        "    m = re.search(r\"_([A-H]\\d{1,2})_\", bn)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Image IO helpers\n",
        "# ============================================================\n",
        "def derive_base_prefix(example_path):\n",
        "    \"\"\"\n",
        "    Strip trailing: _Z####_C##(Name)_M0000_ORG.tif\n",
        "    This preserves the unique field identity (e.g., includes S#### token).\n",
        "    \"\"\"\n",
        "    bn = os.path.basename(example_path)\n",
        "    m = re.search(r\"_Z\\d{4}_C\\d{2}\\([^)]+\\)_M0000_ORG\\.tif$\", bn)\n",
        "    if m:\n",
        "        core = bn[:m.start()]\n",
        "    else:\n",
        "        core = \"_\".join(bn.split(\"_\")[:-3])\n",
        "    return os.path.join(os.path.dirname(example_path), core)\n",
        "\n",
        "\n",
        "def read_single_z_from_anchor(anchor_path, ch_tag, ch_name):\n",
        "    \"\"\"Read the SAME-Z image for a different channel by swapping the channel token.\"\"\"\n",
        "    if ch_tag == \"C00\" and ch_name == \"DAPI\":\n",
        "        target = anchor_path\n",
        "    else:\n",
        "        bn = os.path.basename(anchor_path)\n",
        "        dirn = os.path.dirname(anchor_path)\n",
        "        new_bn = re.sub(r\"C00\\(DAPI\\)\", f\"{ch_tag}({ch_name})\", bn)\n",
        "        target = os.path.join(dirn, new_bn)\n",
        "\n",
        "    if not os.path.exists(target):\n",
        "        raise FileNotFoundError(f\"No file found for derived path: {target}\")\n",
        "\n",
        "    return imread(target)\n",
        "\n",
        "\n",
        "def read_channel_maxproj_from_anchor(anchor_path, ch_tag, ch_name, z_range):\n",
        "    \"\"\"\n",
        "    Max-intensity projection for a channel stack at the SAME field-of-view.\n",
        "    If no planes are found, fall back to the single-Z derived from the anchor.\n",
        "    \"\"\"\n",
        "    base_prefix = derive_base_prefix(anchor_path)\n",
        "    planes = []\n",
        "\n",
        "    for z in z_range:\n",
        "        z_code = f\"Z{z:04d}\"\n",
        "        fp = f\"{base_prefix}_{z_code}_{ch_tag}({ch_name})_M0000_ORG.tif\"\n",
        "        if os.path.exists(fp):\n",
        "            planes.append(imread(fp))\n",
        "\n",
        "    if planes:\n",
        "        return np.stack(planes, axis=0).max(axis=0)\n",
        "\n",
        "    return read_single_z_from_anchor(anchor_path, ch_tag, ch_name)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Anchor selection: one DAPI per field (any-Z)\n",
        "# ============================================================\n",
        "def choose_anchor_dapi_per_field(root, target_plates=None, prefer_z=10):\n",
        "    \"\"\"\n",
        "    Find all DAPI images at any Z, group by field, choose one anchor per field.\n",
        "    Prefer Z0010 if present; otherwise pick a middle Z.\n",
        "    \"\"\"\n",
        "    patt = os.path.join(root, \"**\", \"*_Z????_C00(DAPI)_M0000_ORG.tif\")\n",
        "    all_dapi = sorted(glob.glob(patt, recursive=True))\n",
        "\n",
        "    if target_plates is not None:\n",
        "        tset = set(target_plates)\n",
        "        all_dapi = [p for p in all_dapi if parse_plate_from_name(p) in tset]\n",
        "\n",
        "    z_re = re.compile(r\"_Z(\\d{4})_C00\\(DAPI\\)_M0000_ORG\\.tif$\")\n",
        "\n",
        "    by_field = {}  # base_prefix -> set(Z)\n",
        "    for fp in all_dapi:\n",
        "        mz = z_re.search(os.path.basename(fp))\n",
        "        if not mz:\n",
        "            continue\n",
        "        z_int = int(mz.group(1))\n",
        "        base = derive_base_prefix(fp)\n",
        "        by_field.setdefault(base, set()).add(z_int)\n",
        "\n",
        "    anchors = []\n",
        "    for base, zs in by_field.items():\n",
        "        zs_sorted = sorted(zs)\n",
        "        z_pick = prefer_z if prefer_z in zs else zs_sorted[len(zs_sorted) // 2]\n",
        "        anchor = f\"{base}_Z{z_pick:04d}_C00(DAPI)_M0000_ORG.tif\"\n",
        "        if os.path.exists(anchor):\n",
        "            anchors.append(anchor)\n",
        "\n",
        "    return sorted(anchors)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Per-well cutoffs\n",
        "# ============================================================\n",
        "def load_per_well_cutoffs(path):\n",
        "    \"\"\"Load per-well cutoffs CSV with required columns.\"\"\"\n",
        "    dfc = pd.read_csv(path, low_memory=False)\n",
        "    dfc.columns = [c.strip().lower() for c in dfc.columns]\n",
        "\n",
        "    need = {\"plate\", \"well\", \"channel\", \"cutoff_linear\"}\n",
        "    if not need.issubset(set(dfc.columns)):\n",
        "        raise KeyError(f\"Per-well cutoff CSV must have {need}, got {set(dfc.columns)}\")\n",
        "\n",
        "    dfc[\"plate\"] = pd.to_numeric(dfc[\"plate\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    dfc[\"well\"] = dfc[\"well\"].astype(str).str.strip()\n",
        "    dfc[\"channel\"] = dfc[\"channel\"].astype(str).str.strip()\n",
        "    dfc[\"cutoff_linear\"] = pd.to_numeric(dfc[\"cutoff_linear\"], errors=\"coerce\")\n",
        "    return dfc\n",
        "\n",
        "\n",
        "CUTOFFS = load_per_well_cutoffs(cutoff_csv_path)\n",
        "\n",
        "\n",
        "def get_cutoffs_for_plate_well(dfc, plate, well):\n",
        "    \"\"\"Return (AF594 cutoff, AF647 cutoff) for a given (plate, well).\"\"\"\n",
        "    if plate is None or well is None:\n",
        "        return (None, None)\n",
        "\n",
        "    dfp = dfc[(dfc[\"plate\"].astype(str) == str(plate)) & (dfc[\"well\"] == str(well))].copy()\n",
        "    if dfp.empty:\n",
        "        return (None, None)\n",
        "\n",
        "    c594 = dfp.loc[dfp[\"channel\"].str.contains(\"594\", case=False, na=False), \"cutoff_linear\"].dropna()\n",
        "    c647 = dfp.loc[dfp[\"channel\"].str.contains(\"647\", case=False, na=False), \"cutoff_linear\"].dropna()\n",
        "\n",
        "    return (\n",
        "        float(c594.iloc[0]) if len(c594) else None,\n",
        "        float(c647.iloc[0]) if len(c647) else None\n",
        "    )\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Display scaling (simple, standard)\n",
        "# ============================================================\n",
        "def clip_and_scale(img, vmin, vmax):\n",
        "    \"\"\"Clip to [vmin, vmax] then rescale to [0,1].\"\"\"\n",
        "    x = np.asarray(img, dtype=float)\n",
        "    x = np.clip(x, vmin, vmax)\n",
        "    x = (x - vmin) / (vmax - vmin + 1e-9)\n",
        "    return np.clip(x, 0, 1)\n",
        "\n",
        "\n",
        "def robust_window(img, p_lo=1.0, p_hi=99.8):\n",
        "    \"\"\"Compute a percentile window for display.\"\"\"\n",
        "    x = np.asarray(img, dtype=float)\n",
        "    vmin = float(np.nanpercentile(x, p_lo))\n",
        "    vmax = float(np.nanpercentile(x, p_hi))\n",
        "\n",
        "    if (not np.isfinite(vmin)) or (not np.isfinite(vmax)) or (vmax <= vmin):\n",
        "        vmin, vmax = float(np.nanmin(x)), float(np.nanmax(x))\n",
        "\n",
        "    if vmax <= vmin:\n",
        "        vmax = vmin + 1.0\n",
        "\n",
        "    return vmin, vmax\n",
        "\n",
        "\n",
        "def two_color_blue_green(dapi, af488, dapi_window, p_lo, p_hi, gamma=1.0):\n",
        "    \"\"\"\n",
        "    Build a simple RGB: DAPI->blue, AF488->green.\n",
        "    Uses standard percentile windowing and optional gamma.\n",
        "    \"\"\"\n",
        "    d = clip_and_scale(dapi, *dapi_window)\n",
        "\n",
        "    vmin488, vmax488 = robust_window(af488, p_lo=p_lo, p_hi=p_hi)\n",
        "    g = clip_and_scale(af488, vmin488, vmax488)\n",
        "\n",
        "    if gamma is not None and float(gamma) != 1.0:\n",
        "        g = np.power(g, float(gamma))\n",
        "\n",
        "    r = np.zeros_like(d)\n",
        "    rgb = np.stack([r, g, d], axis=-1)\n",
        "    return rgb, vmin488, vmax488\n",
        "\n",
        "\n",
        "def grayscale_bg(two_col):\n",
        "    \"\"\"Convert the two-color panel to a neutral grayscale background.\"\"\"\n",
        "    bg = 0.25 * two_col[..., 0] + 0.60 * two_col[..., 1] + 0.15 * two_col[..., 2]\n",
        "    bg = np.clip(bg, 0, 1)\n",
        "    return np.stack([bg, bg, bg], axis=-1)\n",
        "\n",
        "\n",
        "def overlay_classification(bg_rgb, mask594, mask647, alpha=0.92):\n",
        "    \"\"\"\n",
        "    Overlay classification:\n",
        "      - AF594-only => purple\n",
        "      - AF647-only => red\n",
        "      - others => background\n",
        "    \"\"\"\n",
        "    out = bg_rgb.copy()\n",
        "\n",
        "    purple = mask594 & (~mask647)\n",
        "    red    = mask647 & (~mask594)\n",
        "\n",
        "    overlay = np.zeros_like(out)\n",
        "    overlay[..., 0] = red.astype(float) + purple.astype(float)  # R\n",
        "    overlay[..., 2] = purple.astype(float)                      # B\n",
        "\n",
        "    m = (red | purple)[..., None]\n",
        "    return np.where(m, (1 - alpha) * out + alpha * overlay, out)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Segmentation\n",
        "# ============================================================\n",
        "def segment_nuclei(dapi_img):\n",
        "    \"\"\"Segment nuclei mask from DAPI using Cellpose (if available) or Otsu.\"\"\"\n",
        "    if USE_CELLPOSE:\n",
        "        try:\n",
        "            model = models.Cellpose(gpu=False, model_type=\"nuclei\")\n",
        "            masks, *_ = model.eval(\n",
        "                [dapi_img],\n",
        "                channels=[0, 0],\n",
        "                diameter=None,\n",
        "                flow_threshold=0.4,\n",
        "                cellprob_threshold=0.0,\n",
        "            )\n",
        "            nuc = masks[0] > 0\n",
        "            nuc = remove_small_objects(nuc, 64)\n",
        "            nuc = remove_small_holes(nuc, 64)\n",
        "            nuc = clear_border(nuc)\n",
        "            nuc = dilation(nuc, footprint=disk(1))\n",
        "            return nuc\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    thr = threshold_otsu(dapi_img.astype(np.float32))\n",
        "    nuc = dapi_img > thr\n",
        "    nuc = remove_small_objects(nuc, 64)\n",
        "    nuc = remove_small_holes(nuc, 64)\n",
        "    nuc = clear_border(nuc)\n",
        "    nuc = dilation(nuc, footprint=disk(1))\n",
        "    return nuc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Classification (per nucleus mean; exclusive)\n",
        "# ============================================================\n",
        "def classify_cells_by_channel(nuc_mask, af594, af647, cutoff594, cutoff647):\n",
        "    \"\"\"\n",
        "    For each connected nucleus:\n",
        "      - compute mean(AF594) and mean(AF647)\n",
        "      - apply per-well cutoffs\n",
        "      - assign AF594-only or AF647-only, otherwise unclassified\n",
        "    Returns:\n",
        "      mask594_only, mask647_only, n_nuclei, n594, n647, n_unclassified\n",
        "    \"\"\"\n",
        "    labels = label(nuc_mask)\n",
        "    nlab = int(labels.max())\n",
        "\n",
        "    mask594_only = np.zeros_like(nuc_mask, dtype=bool)\n",
        "    mask647_only = np.zeros_like(nuc_mask, dtype=bool)\n",
        "\n",
        "    if cutoff594 is None or cutoff647 is None:\n",
        "        return mask594_only, mask647_only, nlab, 0, 0, nlab\n",
        "    if (not np.isfinite(cutoff594)) or (not np.isfinite(cutoff647)):\n",
        "        return mask594_only, mask647_only, nlab, 0, 0, nlab\n",
        "\n",
        "    n_594 = n_647 = n_un = 0\n",
        "\n",
        "    for lab_id in range(1, nlab + 1):\n",
        "        cell_mask = (labels == lab_id)\n",
        "        if not np.any(cell_mask):\n",
        "            continue\n",
        "\n",
        "        m594 = float(af594[cell_mask].mean())\n",
        "        m647 = float(af647[cell_mask].mean())\n",
        "\n",
        "        is594 = m594 > cutoff594\n",
        "        is647 = m647 > cutoff647\n",
        "\n",
        "        if is594 and not is647:\n",
        "            mask594_only[cell_mask] = True\n",
        "            n_594 += 1\n",
        "        elif is647 and not is594:\n",
        "            mask647_only[cell_mask] = True\n",
        "            n_647 += 1\n",
        "        else:\n",
        "            n_un += 1\n",
        "\n",
        "    return mask594_only, mask647_only, nlab, n_594, n_647, n_un\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Process one anchor -> save 1x2 panel\n",
        "# ============================================================\n",
        "def process_one(anchor_path, outdir):\n",
        "    \"\"\"\n",
        "    Build:\n",
        "      - Left: DAPI + AF488 (MIP) panel\n",
        "      - Right: classification overlay (AF594/AF647 MIPs + per-well cutoffs)\n",
        "    \"\"\"\n",
        "    # Anchor DAPI (single Z)\n",
        "    dapi = read_single_z_from_anchor(anchor_path, *CHANNEL_TAGS[\"DAPI\"])\n",
        "\n",
        "    # Visualization channel: AF488 MIP\n",
        "    af488 = read_channel_maxproj_from_anchor(anchor_path, *CHANNEL_TAGS[\"AF488\"], z_range=Z_RANGE)\n",
        "\n",
        "    # Classification channels: AF594 + AF647 MIPs (important!)\n",
        "    af594 = read_channel_maxproj_from_anchor(anchor_path, *CHANNEL_TAGS[\"AF594\"], z_range=Z_RANGE)\n",
        "    af647 = read_channel_maxproj_from_anchor(anchor_path, *CHANNEL_TAGS[\"AF647\"], z_range=Z_RANGE)\n",
        "\n",
        "    # Plate / well + cutoffs\n",
        "    plate = parse_plate_from_name(anchor_path)\n",
        "    well  = parse_folder_well_from_path(anchor_path)\n",
        "    cutoff_594, cutoff_647 = get_cutoffs_for_plate_well(CUTOFFS, plate, well)\n",
        "\n",
        "    # Segment nuclei\n",
        "    nuc = segment_nuclei(dapi)\n",
        "\n",
        "    # Classify nuclei\n",
        "    mask594, mask647, n_nuc, n594, n647, nun = classify_cells_by_channel(\n",
        "        nuc, af594, af647, cutoff_594, cutoff_647\n",
        "    )\n",
        "\n",
        "    # Build display panels\n",
        "    two, vmin488, vmax488 = two_color_blue_green(\n",
        "        dapi, af488,\n",
        "        dapi_window=DISP_DAPI,\n",
        "        p_lo=AF488_P_LO, p_hi=AF488_P_HI,\n",
        "        gamma=AF488_GAMMA\n",
        "    )\n",
        "    bg = grayscale_bg(two)\n",
        "    over = overlay_classification(bg, mask594, mask647, alpha=0.92)\n",
        "\n",
        "    # Plot + save\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "    axes[0].imshow(two)\n",
        "    axes[0].set_title(\n",
        "        f\"DAPI (blue) + 53BP1 AF488 (green)\\n\"\n",
        "        f\"AF488 window p{AF488_P_LO}-p{AF488_P_HI}, gamma={AF488_GAMMA}\"\n",
        "    )\n",
        "\n",
        "    axes[1].imshow(over)\n",
        "    if cutoff_594 is not None and cutoff_647 is not None and np.isfinite(cutoff_594) and np.isfinite(cutoff_647):\n",
        "        axes[1].set_title(\n",
        "            f\"Classified (per-well cutoffs)\\n\"\n",
        "            f\"AF594-only purple | AF647-only red | unclassified grayscale\\n\"\n",
        "            f\"plate={plate} well={well}  594>{cutoff_594:.2f}  647>{cutoff_647:.2f}\"\n",
        "        )\n",
        "    else:\n",
        "        axes[1].set_title(f\"Classified (per-well cutoffs)\\nplate={plate} well={well} (cutoffs missing)\")\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    rel = os.path.relpath(anchor_path, data_dir).replace(\"/\", \"__\")\n",
        "    base_bn = rel.replace(\"_C00(DAPI)_M0000_ORG.tif\", \"\")\n",
        "    out_path = os.path.join(outdir, f\"{base_bn}_two_panel_classified.png\")\n",
        "\n",
        "    plt.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    return {\n",
        "        \"image_anchor\": os.path.relpath(anchor_path, data_dir),\n",
        "        \"panel_path\": os.path.relpath(out_path, data_dir),\n",
        "        \"plate\": plate,\n",
        "        \"well\": well,\n",
        "        \"cutoff_594\": cutoff_594,\n",
        "        \"cutoff_647\": cutoff_647,\n",
        "        \"af488_vmin\": float(vmin488),\n",
        "        \"af488_vmax\": float(vmax488),\n",
        "        \"af488_gamma\": float(AF488_GAMMA),\n",
        "        \"n_nuclei\": int(n_nuc),\n",
        "        \"n_594_only\": int(n594),\n",
        "        \"n_647_only\": int(n647),\n",
        "        \"n_unclassified\": int(nun),\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Main run\n",
        "# ============================================================\n",
        "anchors = choose_anchor_dapi_per_field(data_dir, target_plates=TARGET_PLATES, prefer_z=10)\n",
        "print(f\"Found {len(anchors)} field anchors for plates {sorted(TARGET_PLATES)}.\")\n",
        "\n",
        "completed = load_completed_sets()\n",
        "processed = skipped = 0\n",
        "\n",
        "for p in anchors:\n",
        "    anchor_rel = os.path.relpath(p, data_dir)\n",
        "\n",
        "    rel_for_name = anchor_rel.replace(\"/\", \"__\")\n",
        "    base_bn = rel_for_name.replace(\"_C00(DAPI)_M0000_ORG.tif\", \"\")\n",
        "    fig_path = os.path.join(output_dir, f\"{base_bn}_two_panel_classified.png\")\n",
        "\n",
        "    if (not FORCE_RERUN) and (anchor_rel in completed) and os.path.exists(fig_path):\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        row = process_one(p, output_dir)\n",
        "        append_row_to_csv(row)\n",
        "        processed += 1\n",
        "        print(f\"✔ {anchor_rel}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✖ {anchor_rel} -> {e}\")\n",
        "\n",
        "print(f\"\\nDone. Processed: {processed} | Skipped: {skipped}\")\n",
        "print(f\"Panels -> {output_dir}\")\n",
        "print(f\"Metrics CSV -> {csv_out_path}\")\n",
        "print(f\"Done list -> {done_list_path}\")\n"
      ]
    }
  ]
}
